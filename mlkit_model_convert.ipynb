{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "923392f3-4cae-4ca7-9ba9-7acb6c6c54c8",
   "metadata": {},
   "source": [
    "# Prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66851e3d-2398-494c-a1d1-1dba98d5556c",
   "metadata": {},
   "source": [
    "NOTE: If running this after training the model, shut down the other kernel to make sure that there is enough memory to initialize cuDNN here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03a589d-f609-48f2-815e-db1029fd8ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure that the latest version of the package is installed (may not happen if no wheels support the version of Python installed)\n",
    "!pip install tflite-support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a5f0d4-35ee-4d75-8f8b-e155fbaedd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Disable tensorflow warnings to clean up cell output\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "900ff85e-873e-4c1e-90aa-89d52bafd88e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from tflite_support.task.vision import ImageClassifier, TensorImage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0eda96e-5351-404b-b820-3633a2e27158",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d85218-5c3f-42ba-b6bb-841193ba4eba",
   "metadata": {},
   "source": [
    "# Convert model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11e78384-59f8-4d0f-91b2-27072bc013ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 62). These functions will not be directly callable after loading.\n"
     ]
    }
   ],
   "source": [
    "# We load the Keras model as we will reuse it in testing later\n",
    "model = keras.models.load_model(\"car_detection_model\")\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49d8d738-11e5-4b26-b148-11ac3b0c6970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to object_labeler.tflite\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model_file = 'object_labeler.tflite'\n",
    "with open(model_file, 'wb') as f:\n",
    "  f.write(tflite_model)\n",
    "print(\"Saved model to {}\".format(model_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8088568d-b1e2-46c5-8033-e5047276c76a",
   "metadata": {},
   "source": [
    "# Add metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce8c692c-e30d-4494-8673-1c67386b1b15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This was saved earlier in mlkit_model_training.ipynb\n",
    "label_map_file = \"cars196_label_map.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08e56f7d-5212-42ed-90e3-658db4312a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add metadata (taken from https://www.tensorflow.org/lite/models/convert/metadata)\n",
    "from tflite_support import flatbuffers\n",
    "from tflite_support import metadata as _metadata\n",
    "from tflite_support import metadata_schema_py_generated as _metadata_fb\n",
    "\n",
    "model_meta = _metadata_fb.ModelMetadataT()\n",
    "model_meta.name = \"MobileNetV3 image classifier\"\n",
    "model_meta.description = (\"Identify the most prominent object in the \"\n",
    "                          \"image from a set of 196 categories of cars.\")\n",
    "model_meta.version = \"v1\"\n",
    "model_meta.author = \"Kevin Hung\"\n",
    "model_meta.license = (\"Apache License. Version 2.0 \"\n",
    "                      \"http://www.apache.org/licenses/LICENSE-2.0.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7adefb-567d-4469-85c6-49fc0bc3376a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the following metadata to input tensor TensorMetadata as MLKit input tensor is of type kTfLiteFloat32\n",
    "# NormalizationOptions:\n",
    "# Set normalization to [0, 255] to match MobileNetV3 with preprocessing layer\n",
    "input_meta = _metadata_fb.TensorMetadataT()\n",
    "input_meta.name = \"image\"\n",
    "input_meta.description = (\n",
    "    \"Input image to be classified. The expected image is {0} x {1}, with \"\n",
    "    \"three channels (red, blue, and green) per pixel. Each value in the \"\n",
    "    \"tensor is a single float between 0 and 255.\".format(224, 224))\n",
    "input_meta.content = _metadata_fb.ContentT()\n",
    "input_meta.content.contentProperties = _metadata_fb.ImagePropertiesT()\n",
    "input_meta.content.contentProperties.colorSpace = (\n",
    "    _metadata_fb.ColorSpaceType.RGB)\n",
    "input_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.ImageProperties)\n",
    "input_normalization = _metadata_fb.ProcessUnitT()\n",
    "input_normalization.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.NormalizationOptions)\n",
    "input_normalization.options = _metadata_fb.NormalizationOptionsT()\n",
    "# Don't normalize as it will be done in the preprocessing layer of the model\n",
    "input_normalization.options.mean = [0.]\n",
    "input_normalization.options.std = [1.]\n",
    "input_meta.processUnits = [input_normalization]\n",
    "input_stats = _metadata_fb.StatsT()\n",
    "input_stats.max = [255]\n",
    "input_stats.min = [0]\n",
    "input_meta.stats = input_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f14034bc-519b-4089-b0f7-41a2bdfb735a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the following metadata to output tensor TensorMetadata\n",
    "# label map as AssociatedFile with type TENSOR_AXIS_LABELS\n",
    "# default score threshold as ProcessUnit with ScoreThresholdingOptions\n",
    "\n",
    "output_meta = _metadata_fb.TensorMetadataT()\n",
    "output_meta.name = \"probability\"\n",
    "output_meta.description = \"Probabilities of the labels.\"\n",
    "output_meta.content = _metadata_fb.ContentT()\n",
    "output_meta.content.contentProperties = _metadata_fb.FeaturePropertiesT()\n",
    "output_meta.content.contentPropertiesType = (\n",
    "    _metadata_fb.ContentProperties.FeatureProperties)\n",
    "output_stats = _metadata_fb.StatsT()\n",
    "output_stats.max = [1.0]\n",
    "output_stats.min = [0.0]\n",
    "output_meta.stats = output_stats\n",
    "label_file = _metadata_fb.AssociatedFileT()\n",
    "label_file.name = os.path.basename(label_map_file)\n",
    "label_file.description = \"Labels for objects that the model can recognize.\"\n",
    "label_file.type = _metadata_fb.AssociatedFileType.TENSOR_AXIS_LABELS\n",
    "output_meta.associatedFiles = [label_file]\n",
    "\n",
    "# Threshold on 0.9 score to prevent spurious labeling\n",
    "output_thresholding = _metadata_fb.ProcessUnitT()\n",
    "output_thresholding.optionsType = (\n",
    "    _metadata_fb.ProcessUnitOptions.ScoreThresholdingOptions)\n",
    "output_thresholding.options = _metadata_fb.ScoreThresholdingOptionsT()\n",
    "output_thresholding.options.globalScoreThreshold = 0.9\n",
    "output_meta.processUnits = [output_thresholding]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d852a08-d265-462f-ba4c-b7e0143f372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates subgraph info.\n",
    "subgraph = _metadata_fb.SubGraphMetadataT()\n",
    "subgraph.inputTensorMetadata = [input_meta]\n",
    "subgraph.outputTensorMetadata = [output_meta]\n",
    "model_meta.subgraphMetadata = [subgraph]\n",
    "\n",
    "b = flatbuffers.Builder(0)\n",
    "b.Finish(\n",
    "    model_meta.Pack(b),\n",
    "    _metadata.MetadataPopulator.METADATA_FILE_IDENTIFIER)\n",
    "metadata_buf = b.Output()\n",
    "\n",
    "# Pack\n",
    "populator = _metadata.MetadataPopulator.with_model_file(model_file)\n",
    "populator.load_metadata_buffer(metadata_buf)\n",
    "populator.load_associated_files([label_map_file])\n",
    "populator.populate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bf6541f-ecc4-48b6-afac-6509b7f49778",
   "metadata": {},
   "source": [
    "# Confirm that the TFLite model works like the TF model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906a1b96-4302-44b0-a93a-a415f743ed3b",
   "metadata": {},
   "source": [
    "Load sample data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec54702a-8e42-488f-b6d8-534e0899ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image as size of input (224, 224)\n",
    "image = tf.keras.utils.load_img('example.png', target_size=(224, 224))\n",
    "x = tf.keras.utils.img_to_array(image)\n",
    "# Make single instance into a batch\n",
    "x = np.array([x])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bc60fe-c050-45bc-8f3c-e3627e53252c",
   "metadata": {},
   "source": [
    "Predict with original TensorFlow model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07b5c287-77bb-4bd0-96a8-a6d55ebc9367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map labels\n",
    "with open(label_map_file, 'r') as f:\n",
    "    classes = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b3549f7-76c4-4504-8ff9-e529416d3d93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "TF prediction: Cadillac SRX SUV 2012 (51) @ 0.994\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x)\n",
    "class_idx = np.argmax(predictions[0])\n",
    "print(\"TF prediction: {0} ({1}) @ {2:0.3f}\".format(classes[class_idx], class_idx, np.max(predictions[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10643a4c-ae23-43e5-ae1f-c0402d3c3893",
   "metadata": {},
   "source": [
    "Predict with TensorFlow Lite model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0720513a-671e-4cac-8de8-13c3993f6846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TFLite prediction: Cadillac SRX SUV 2012 (51) @ 0.994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# https://www.tensorflow.org/lite/api_docs/python/tf/lite/Interpreter\n",
    "# We load from the file as it's the \"final\" version\n",
    "interpreter = tf.lite.Interpreter(model_path=model_file)\n",
    "interpreter.allocate_tensors()\n",
    "output = interpreter.get_output_details()[0]\n",
    "input = interpreter.get_input_details()[0]\n",
    "interpreter.set_tensor(input['index'], x)\n",
    "interpreter.invoke()\n",
    "predictions = interpreter.get_tensor(output['index'])\n",
    "print(\"TFLite prediction: {0} ({1}) @ {2:0.3f}\".format(classes[class_idx], class_idx, np.max(predictions[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "803baaa7-f9c0-4058-ae7d-b95f31c650a9",
   "metadata": {},
   "source": [
    "Check that the metadata has been added correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afe5f963-759d-4705-af39-2138dd6cf719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata:\n",
      "{\n",
      "  \"name\": \"MobileNetV3 image classifier\",\n",
      "  \"description\": \"Identify the most prominent object in the image from a set of 196 categories of cars.\",\n",
      "  \"version\": \"v1\",\n",
      "  \"subgraph_metadata\": [\n",
      "    {\n",
      "      \"input_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"image\",\n",
      "          \"description\": \"Input image to be classified. The expected image is 224 x 224, with three channels (red, blue, and green) per pixel. Each value in the tensor is a single float between 0 and 255.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"ImageProperties\",\n",
      "            \"content_properties\": {\n",
      "              \"color_space\": \"RGB\"\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"NormalizationOptions\",\n",
      "              \"options\": {\n",
      "                \"mean\": [\n",
      "                  0.0\n",
      "                ],\n",
      "                \"std\": [\n",
      "                  1.0\n",
      "                ]\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              255.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              0.0\n",
      "            ]\n",
      "          }\n",
      "        }\n",
      "      ],\n",
      "      \"output_tensor_metadata\": [\n",
      "        {\n",
      "          \"name\": \"probability\",\n",
      "          \"description\": \"Probabilities of the labels.\",\n",
      "          \"content\": {\n",
      "            \"content_properties_type\": \"FeatureProperties\",\n",
      "            \"content_properties\": {\n",
      "            }\n",
      "          },\n",
      "          \"process_units\": [\n",
      "            {\n",
      "              \"options_type\": \"ScoreThresholdingOptions\",\n",
      "              \"options\": {\n",
      "                \"global_score_threshold\": 0.9\n",
      "              }\n",
      "            }\n",
      "          ],\n",
      "          \"stats\": {\n",
      "            \"max\": [\n",
      "              1.0\n",
      "            ],\n",
      "            \"min\": [\n",
      "              0.0\n",
      "            ]\n",
      "          },\n",
      "          \"associated_files\": [\n",
      "            {\n",
      "              \"name\": \"cars196_label_map.txt\",\n",
      "              \"description\": \"Labels for objects that the model can recognize.\",\n",
      "              \"type\": \"TENSOR_AXIS_LABELS\"\n",
      "            }\n",
      "          ]\n",
      "        }\n",
      "      ]\n",
      "    }\n",
      "  ],\n",
      "  \"author\": \"Kevin Hung\",\n",
      "  \"license\": \"Apache License. Version 2.0 http://www.apache.org/licenses/LICENSE-2.0.\",\n",
      "  \"min_parser_version\": \"1.0.0\"\n",
      "}\n",
      "\n",
      "associated files:\n",
      "['cars196_label_map.txt']\n"
     ]
    }
   ],
   "source": [
    "displayer = _metadata.MetadataDisplayer.with_model_file(model_file)\n",
    "print(\"metadata:\")\n",
    "print(displayer.get_metadata_json())\n",
    "print(\"associated files:\")\n",
    "print(displayer.get_packed_associated_file_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f5b1ccf-4768-4106-9b6c-1771910ddccc",
   "metadata": {},
   "source": [
    "Check that the model works end-to-end with the TFLite API calls:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d919082f-9d95-4d5e-a1cd-89bc21496621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category(index=51, score=0.9874402284622192, display_name='', category_name='Cadillac SRX SUV 2012')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# ImageClassifier usage: https://www.tensorflow.org/lite/inference_with_metadata/task_library/image_classifier\n",
    "tensorimg = TensorImage.create_from_file('example.png')\n",
    "classifier = ImageClassifier.create_from_file(model_file)\n",
    "prediction = classifier.classify(tensorimg)\n",
    "if len(prediction.classifications[0].categories) > 0:\n",
    "    result = prediction.classifications[0].categories[0]\n",
    "else:\n",
    "    result = prediction.classifications[0].categories\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "043855de-793f-474d-bffa-17eb49f61bf1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (tf-py39)",
   "language": "python",
   "name": "tf39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
